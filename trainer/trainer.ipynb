{"nbformat":4,"nbformat_minor":5,"metadata":{"notebookId":"aee86e15-2fd5-423e-8fe9-a6beaa6f8229","language_info":{"pygments_lexer":"ipython3","file_extension":".py","version":"3.7.7","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"name":"python","nbconvert_exporter":"python"},"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"}},"cells":[{"cell_type":"code","source":"%pip install wandb","metadata":{"cellId":"umgipoldmnohaginjyqi6","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nCollecting wandb\n  Downloading wandb-0.10.25-py2.py3-none-any.whl (2.1 MB)\n\u001B[K     |████████████████████████████████| 2.1 MB 3.7 MB/s \n\u001B[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (5.3.1)\nRequirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.1)\nRequirement already satisfied: psutil>=5.0.0 in /kernel/lib/python3.7/site-packages (from wandb) (5.7.3)\nRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.15.6)\nRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\nRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\nRequirement already satisfied: six>=1.13.0 in /kernel/lib/python3.7/site-packages (from wandb) (1.15.0)\nCollecting docker-pycreds>=0.4.0\n  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\nRequirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (4.0.2)\nRequirement already satisfied: python-dateutil>=2.6.1 in /kernel/lib/python3.7/site-packages (from wandb) (2.8.1)\nRequirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.14)\nCollecting sentry-sdk>=0.4.0\n  Downloading sentry_sdk-1.0.0-py2.py3-none-any.whl (131 kB)\n\u001B[K     |████████████████████████████████| 131 kB 18.9 MB/s \n\u001B[?25hCollecting pathtools\n  Downloading pathtools-0.1.2.tar.gz (11 kB)\nRequirement already satisfied: requests<3,>=2.0.0 in /kernel/lib/python3.7/site-packages (from wandb) (2.25.1)\nCollecting subprocess32>=3.5.3\n  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n\u001B[K     |████████████████████████████████| 97 kB 5.8 MB/s \n\u001B[?25hRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.5)\nRequirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.5)\nRequirement already satisfied: chardet<5,>=3.0.2 in /kernel/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\nRequirement already satisfied: idna<3,>=2.5 in /kernel/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /kernel/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.26.4)\nRequirement already satisfied: certifi>=2017.4.17 in /kernel/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\nBuilding wheels for collected packages: subprocess32, pathtools\n  Building wheel for subprocess32 (setup.py) ... \u001B[?25ldone\n\u001B[?25h  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6488 sha256=42f2826b8e6101c079c4520c929135262837b78c254702a3eec634a52d345b8e\n  Stored in directory: /home/jupyter/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n  Building wheel for pathtools (setup.py) ... \u001B[?25ldone\n\u001B[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8784 sha256=adccbc3b5afb98ef5a791b568505a45e166e8938ddaf476393a8b9876a875026\n  Stored in directory: /home/jupyter/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\nSuccessfully built subprocess32 pathtools\nInstalling collected packages: subprocess32, sentry-sdk, pathtools, docker-pycreds, wandb\n\u001B[33m  WARNING: The scripts wandb and wb are installed in '/home/jupyter/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001B[0m\nSuccessfully installed docker-pycreds-0.4.0 pathtools-0.1.2 sentry-sdk-1.0.0 subprocess32-3.5.4 wandb-0.10.25\n"}],"execution_count":39},{"cell_type":"code","source":"from collections import defaultdict\nfrom pathlib import Path\nfrom typing import List, Optional\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.utils as utils\nfrom torch.utils.data import DataLoader\nfrom torch import optim\nfrom tqdm import tqdm\nimport wandb\n\nfrom model_base import ModelBase","metadata":{"cellId":"yv0p4iq7nksx1wvbewdcz","trusted":true},"outputs":[],"execution_count":60},{"cell_type":"code","source":"class Trainer():\n    def __init__(self, \n                 model: nn.Module,\n                 config: dict,\n                 optimizers: list, # [(label, opt)]\n                 train_loader: DataLoader,\n                 val_loader: DataLoader=None,\n                 scheduler=None):\n        self.model = model\n        self.config = config\n        self.optimizers = self.model.configure_optimizers()\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        self.scheduler = scheduler\n        self.history = {\"train\": defaultdict(list), \n                        \"val\": defaultdict(list)}\n\n    def save_checkpoint(self,\n                        epoch: int,\n                        checkpoint_path: Path,\n                        ) -> None:\n        checkpoint = {\n            \"model\": self.model,\n            \"model_state_dict\": self.model.state_dict(),\n            \"epoch\": epoch,\n        }\n\n        for opt in optimizers:\n            label = opt[\"label\"]\n            optimizer = opt[\"value\"]\n\n            checkpoint[f\"optimizer_{label}\"] = optimizer\n            checkpoint[f\"optimizer_{label}_state_dict\"] = optimizer.state_dict()\n\n        torch.save(checkpoint, checkpoint_path)\n\n    def load_checkpoint(self, \n                        checkpoint_path: Path,\n                        ) -> None:\n        checkpoint = torch.load(checkpoint_path)\n        self.model.load_state_dict(checkpoint[\"model_state_dict\"])\n\n        for opt in optimizers:\n            label = opt[\"label\"]\n            optimizer = opt[\"value\"]\n            optimizer.load_state_dict(checkpoint[f\"optimizer_{label}_state_dict\"])\n\n    @torch.enable_grad()\n    def train_epoch(self,\n                    pbar: tqdm\n                    ) -> None:\n        model.train()\n        \n        for batch_idx, batch in enumerate(tqdm.tqdm(self.train_loader)):\n            for opts in optimizers:\n\n                step = opts[\"label\"]\n                optimizer = opts[\"value\"]\n\n                info = self.model.training_step(batch=batch, \n                                                step=step)\n                loss = info['loss']\n                loss.backward()\n                utils.clip_grad_norm_(parameters=model.parameters(),\n                                      max_norm=10)\n                \n                self._update_history(info)\n                self._update_logs(pbar)\n                \n                optimizer.step()\n                optimizer.zero_grad()\n        \n    def _update_logs(self, pbar: tqdm):\n        pbar.update(1)\n\n        history_train = self.history[\"train\"]\n        postfix_train = {\n            key + \"_train\": history_train[key][-1] for key in history_train\n        }\n\n        history_val = self.history[\"val\"]\n        postfix_val = {\n            key + \"_val\": history_val[key][-1] for key in history_val\n        }\n\n        pbar.set_postfix({**postfix_train, **postfix_val})\n        wandb.log({**postfix_train, **postfix_val})\n\n    def _update_history(self, info):\n        for key in info:\n            if key not in info:\n                print(f\"Warning: not valid key in history - {key}\")\n                continue\n            for inner_key in info[key]:\n                value = info[key][inner_key]\n                if isinstance(inner, torch.Tensor):\n                    value = value.item()\n                self.history[key][inner].append(value)\n\n    def fit(self):\n        n_epochs = self.config[\"n_epochs\"]\n        pbar = tqdm(total=epochs, position=0, leave=True)\n        wandb.init(project=\"test-drive\", config=self.config)\n        wandb.watch(self.model)\n\n        for epoch in range(n_epochs):\n            self._train_epoch(pbar)\n            \n            if epoch % self.save_period == 0:\n                loss = self.history[\"train\"][\"loss\"]\n                checkpoint_path = \\\n                    Path.cwd() / \"models\" / f'loss={loss},e={epoch}.pt'\n                self.save_checkpoint(checkpoint_path, epoch)\n\n                with torch.no_grad():\n                    batch = next(iter(train_dataloader))\n                    sample = model.sample(batch)\n                images = (utils.make_grid(sample, nrow=4).detach().cpu().permute(1,2,0)\n                          * Tensor([0.406, 0.456, 0.485])\n                          + Tensor([0.225, 0.224, 0.229])).numpy()\n                wandb.log({\"generated images\": [wandb.Image(images)]})\n\n        pbar.close()\n        wandb.finish()\n","metadata":{"cellId":"7w2zxdjkp8dbga6spqdwh","trusted":true},"outputs":[],"execution_count":61}]}