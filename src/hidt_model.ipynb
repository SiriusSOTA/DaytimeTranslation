{"nbformat":4,"nbformat_minor":5,"metadata":{"notebookId":"8c84e905-f486-4885-8219-1a040d30d832","language_info":{"file_extension":".py","version":"3.7.7","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3"},"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"}},"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n\nfrom hidt_components import (\n    ConditionalDiscriminator,\n    ContentEncoder,\n    Decoder,\n    StyleEncoder,\n    UnconditionalDiscriminator,\n    MetricCalculator,\n)","metadata":{"cellId":"me3fp4wdhdppe42thztd","trusted":true},"outputs":[],"execution_count":17},{"cell_type":"code","source":"class HiDTModel(Module):\n\n    def __init__(self,\n                 config: dict,\n                 device: torch.device = torch.device(\"cpu\"),\n                 learning_rate: float = 3e-4,\n                 verbose: bool = True,\n                 ):\n        super().__init__()\n\n        self.config = config\n        self.device = device\n        self.verbose = verbose\n\n        self.content_encoder = ContentEncoder()\n        self.style_encoder = StyleEncoder()\n        self.generator = Decoder()\n        self.cond_discriminator = ConditionalDiscriminator()\n        self.uncond_discriminator = UnconditionalDiscriminator()\n\n        self.criterion_dist = MetricCalculator.criterion_dist\n        self.criterion_rec = nn.L1Loss()\n        self.criterion_seg = nn.CrossEntropyLoss()\n        self.criterion_c = nn.L1Loss()\n        self.criterion_s = nn.L1Loss()\n        self.criterion_cyc = nn.L1Loss()\n        self.criterion_seg_r = nn.CrossEntropyLoss()\n        self.criterion_c_r = nn.L1Loss()\n        self.criterion_s_r = nn.L1Loss()\n        self.criterion_rec_r = nn.L1Loss()\n\n        self.lambdas = config[\"lambdas\"]\n\n    def forward(self,\n                x: torch.Tensor\n                ):\n        raise NotImplementedError(\"forward not implemented for this model\")\n\n    def generator_step(self,\n                       x: torch.Tensor,\n                       x_prime: torch.Tensor\n                       ):\n        # autoencoding branch\n\n        c, h = self.content_encoder(x)\n        s = self.style_encoder(x)\n        loss_dist = MetricCalculator.criterion_dist(s)\n        x_tilde, _ = self.generator(content=c, style=s, hooks=h)\n        loss_rec = self.criterion_rec(x_tilde, x)\n\n        # swapping branch\n        s_prime = self.style_encoder(x_prime)\n        x_hat, m_hat = self.generator(content=c, style=s_prime, hooks=h)\n\n        loss_seg = 0  # TODO: self.criterion_seg(m_hat, m)\n        c_hat, h_hat = self.content_encoder(x_hat)\n        s_hat = self.style_encoder(x_hat)\n        loss_c = self.criterion_c(c_hat, c)\n        loss_s = self.criterion_s(s_hat, s_prime)\n\n        c_prime, h_prime = self.content_encoder(x_prime)\n        x_prime_hat, _ = self.generator(content=c_prime, style=s,\n                                        hooks=h_prime)\n        s_prime_hat = self.style_encoder(x_prime_hat)\n        x_hat_tilde, _ = self.generator(content=c_hat, style=s_prime_hat,\n                                        hooks=h_hat)\n        loss_cyc = self.criterion_cyc(x_hat_tilde, x)\n\n        # noise branch\n        s_r = torch.randn(len(x), 3).to(self.device)\n        x_r, m_r = self.generator(content=c, style=s_r, hooks=h)\n        loss_seg_r = 0  # TODO: self.criterion_seg_r(m_r, m)\n        c_r_tilde, h_r_tilde, = self.content_encoder(x_r)\n        s_r_tilde = self.style_encoder(x_r)\n\n        loss_c_r = self.criterion_c_r(c_r_tilde, c)\n        loss_s_r = self.criterion_s_r(s_r_tilde, s_r)\n\n        x_r_tilde, _ = self.generator(content=c_r_tilde, style=s_r_tilde,\n                                      hooks=h_r_tilde)\n        loss_rec_r = self.criterion_rec_r(x_r_tilde, x_r)\n\n        # all discriminators\n        du_x_hat = self.uncond_discriminator(x_hat)\n        dc_x_hat = self.cond_discriminator(x_hat, s_prime.clone().detach())\n\n        loss_adv = (\n                MetricCalculator.criterion_adv(\n                    du_x_hat,\n                    torch.ones_like(du_x_hat)\n                ) +\n                MetricCalculator.criterion_adv(\n                    dc_x_hat,\n                    torch.ones_like(dc_x_hat),\n                )\n        )\n\n        du_x_r = self.uncond_discriminator(x_r)\n        dc_x_r = self.cond_discriminator(x_r, s_r.clone().detach())\n\n        loss_adv_r = (\n                MetricCalculator.criterion_adv(du_x_r,\n                                               torch.ones_like(du_x_r)) +\n                MetricCalculator.criterion_adv(dc_x_r, torch.ones_like(dc_x_r))\n        )\n\n        loss_terms = [\n            loss_adv + loss_adv_r,\n            loss_rec + loss_rec_r + loss_cyc,\n            loss_c + loss_c_r,\n            loss_s,\n            loss_s_r,\n            loss_dist,\n        ]\n\n        loss = 0\n        for i, _ in enumerate(loss_terms):\n            loss += self.lambdas[i] * loss_terms[i]\n\n        info = {'loss': loss,\n                'adversarial loss': loss_adv + loss_adv_r,\n                'image reconstruction loss': loss_rec + loss_rec_r + loss_cyc,\n                'content reconstruction loss': loss_c + loss_c_r,\n                'style reconstruction loss': loss_s,\n                'random style reconstruction loss': loss_s_r,\n                'style distribution loss': loss_dist}\n        return info\n\n    def discriminator_step(self,\n                           x: torch.Tensor,\n                           x_prime: torch.Tensor\n                           ):\n        c, h = self.content_encoder(x)\n        s = self.style_encoder(x)\n        x_tilde, m = self.generator(content=c, style=s, hooks=h)\n\n        # swapping branch\n        s_prime = self.style_encoder(x_prime)\n        x_hat, m_hat = self.generator(content=c, style=s_prime, hooks=h)\n\n        c_hat, h_hat = self.content_encoder(x_hat)\n        s_hat = self.style_encoder(x_hat)\n\n        c_prime, h_prime = self.content_encoder(x_prime)\n        x_prime_hat, _ = self.generator(content=c_prime, style=s,\n                                        hooks=h_prime)\n        s_prime_hat = self.style_encoder(x_prime_hat)\n        x_hat_tilde, _ = self.generator(content=c_hat, style=s_prime_hat,\n                                        hooks=h_hat)\n\n        # noise branch\n        s_r = torch.randn(len(x), 3).to(self.device)\n        x_r, m_r = self.generator(content=c, style=s_r, hooks=h)\n        c_r_tilde, h_r_tilde, = self.content_encoder(x_r)\n        s_r_tilde = self.style_encoder(x_r)\n        x_r_tilde, _ = self.generator(content=c_r_tilde, style=s_r_tilde,\n                                      hooks=h_r_tilde)\n\n        # all discriminators\n        du_x_hat = self.uncond_discriminator(x_hat)\n        dc_x_hat = self.cond_discriminator(x_hat, s_prime.clone().detach())\n        loss_adv_hat = (\n                MetricCalculator.criterion_adv(\n                    du_x_hat,\n                    torch.zeros_like(du_x_hat)\n                )\n                + MetricCalculator.criterion_adv(\n                    dc_x_hat,\n                    torch.zeros_like(dc_x_hat),\n                )\n        )\n\n        du_x_r = self.uncond_discriminator(x_r)\n        dc_x_r = self.cond_discriminator(x_r, s_r.clone().detach())\n\n        loss_adv_r = (\n                MetricCalculator.criterion_adv(\n                    du_x_r,\n                    torch.zeros_like(du_x_r),\n                ) +\n                MetricCalculator.criterion_adv(\n                    dc_x_r,\n                    torch.zeros_like(dc_x_r),\n                )\n        )\n        du_x = self.uncond_discriminator(x)\n        dc_x = self.cond_discriminator(x, s.clone().detach())\n        loss_adv_real = (\n                MetricCalculator.criterion_adv(du_x, torch.ones_like(du_x)) +\n                MetricCalculator.criterion_adv(dc_x, torch.ones_like(dc_x))\n        )\n\n        loss = loss_adv_hat + loss_adv_r + loss_adv_real\n\n        info = {'loss': loss,\n                'loss_adv_hat': loss_adv_hat,\n                'loss_adv_r': loss_adv_r,\n                'loss_adv_real': loss_adv_real}\n\n        return info\n\n    def training_step(self,\n                      batch,\n                      step: str\n                      ):\n        self.train()\n        x, x_prime = batch\n        x = x.to(self.device)\n        x_prime = x_prime.to(self.device)\n\n        if step == \"generator\":  # generator step\n            return self.generator_step(x, x_prime)\n        elif step == \"discriminator\":\n            return self.discriminator_step(x, x_prime)\n\n        raise ValueError(\"step should be 'generator' or discriminator\"\n                         \", received: \" + str(step))\n\n    def validation_step(self, batch):\n        self.eval()\n        loss = self.training_step(batch=batch, step=\"generator\")\n\n        return loss\n\n    @torch.no_grad()\n    def sample(self, batch):\n        self.eval()\n\n        x, x_prime = batch\n        x = x.to(self.device)\n        x_prime = x_prime.to(self.device)\n        c, h = self.content_encoder(x)\n        s = self.style_encoder(x)\n        x_tilde, _ = self.generator(content=c, style=s, hooks=h)\n        s_prime = self.style_encoder(x_prime)\n        x_hat, _ = self.generator(content=c, style=s_prime, hooks=h)\n        s_r = torch.randn(len(x), 3).to(self.device)  # TODO просто нормальное?\n        x_r, _ = self.generator(content=c, style=s_r, hooks=h)\n\n        return torch.cat((x, x_tilde, x_hat, x_r))\n\n    def configure_optimizers(self):\n        params_g = list(self.generator.parameters()) + \\\n                   list(self.content_encoder.parameters()) + \\\n                   list(self.style_encoder.parameters())\n        optimizer_g = optimizer.Adam(\n            params=params_g,\n            lr=self.config[\"learning_rate\"],\n        )\n        params_d = list(self.cond_discriminator.parameters()) + \\\n                   list(self.uncond_discriminator.parameters())\n        optimizer_d = optimizer.Adam(\n            params=params_d,\n            lr=self.config[\"learning_rate\"],\n        )\n\n        optimizers = [\n            {\"label\": \"generator\", \"value\": optimizer_g},\n            {\"label\": \"discriminator\", \"value\": optimizer_d},\n        ]\n        schedulers = []\n\n        return optimizers, schedulers\n","metadata":{"cellId":"6aynkpl2kp2y2vfwxx8w7","trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"!git push --set-upstream origin trainer","metadata":{"cellId":"4bm1ib9yit6h753xkdmt3d","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Username for 'https://github.com': ^C\n"},{"output_type":"error","ename":"Exception","evalue":"Process exited with code -2","traceback":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m","\u001B[0;31mException\u001B[0m                                 Traceback (most recent call last)","\u001B[0;32m<ipython-input-3-6662b920af3e>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mget_ipython\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msystem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'git push --set-upstream origin trainer'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;31m#\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py\u001B[0m in \u001B[0;36m<lambda>\u001B[0;34m(code)\u001B[0m\n\u001B[1;32m    267\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    268\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_script_executor\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mScriptExecutor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mProcessHandler\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msystem\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 269\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshell\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msystem\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mlambda\u001B[0m \u001B[0mcode\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_script_executor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexecute\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"bash\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    270\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    271\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_init_message_handlers\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/kernel/lib/python3.7/site-packages/ml_kernel/script_executor.py\u001B[0m in \u001B[0;36mexecute\u001B[0;34m(self, lang, code)\u001B[0m\n\u001B[1;32m     33\u001B[0m         \u001B[0mreturn_code\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_system\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     34\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mreturn_code\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 35\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mException\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Process exited with code %d'\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0mreturn_code\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m","\u001B[0;31mException\u001B[0m: Process exited with code -2"]}],"execution_count":14},{"cell_type":"code","source":"#!L\n","metadata":{"cellId":"60gb24si52b6ga3ihcojf"},"outputs":[],"execution_count":null}]}